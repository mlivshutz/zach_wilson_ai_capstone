{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88597347-55ff-45b4-ad93-ec5af2ae1b36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install aiohttp\n",
    "%pip install pymilvus\n",
    "%pip install PyGithub\n",
    "%pip install mmh3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c97ae5e-a2c9-4cf6-8ff4-58d37a775005",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3495bb7e-9a0a-4dae-a246-0815bb3d5f1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility\n",
    "import numpy as np\n",
    "import logging\n",
    "import uuid\n",
    "import json\n",
    "import httpx\n",
    "import requests\n",
    "from github import Github\n",
    "import mmh3\n",
    "import datetime\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7fbe941-7f39-48cf-9b7f-2571cda133f7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "setup GitHub repo widget"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"repo\", \"\", \"GitHub Repo\")\n",
    "repo = dbutils.widgets.get(\"repo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4b3f7c3-151e-4977-9e6b-32edcb4d969f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GITHUB_PAT = os.getenv('GITHUB_PAT')\n",
    "ZILLIZ_CLOUD_URI = os.getenv(\"ZILLIZ_CLOUD_URI\")\n",
    "ZILLIZ_API_KEY = os.getenv(\"ZILLIZ_API_KEY\")\n",
    "\n",
    "# OpenAI Model Configuration\n",
    "OPENAI_EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "OPENAI_CHAT_MODEL = \"gpt-4.1-mini\"\n",
    "EMBEDDING_DIMENSION = 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a33d92a7-b68b-484e-b0fe-d73a6c861d74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24abb1e4-1bcc-4909-80f8-f4a6017f4fd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MILVUS_COLLECTION_NAME = \"github_dense_index\"\n",
    "MILVUS_GITHUB_SPARSE_COLLECTION=\"github_sparse_index\"\n",
    "\n",
    "# Global variables\n",
    "collection = None\n",
    "collection_github_sparse = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "152e219e-3e38-43f1-b48d-11f622d8b889",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_openai_client():\n",
    "    \"\"\"Get OpenAI client with error handling\"\"\"\n",
    "    if client is None:\n",
    "        raise Exception(\"OpenAI API key not configured\")\n",
    "    return client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29d97a5e-f2a5-455b-9038-8b29ca205d0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Milvus setup\n",
    "def setup_milvus_collection(collection_name):\n",
    "    \n",
    "    # Check if collection exists\n",
    "    if utility.has_collection(collection_name):\n",
    "        collection = Collection(collection_name)\n",
    "        print(f\"Connected to existing collection: {collection_name}\")\n",
    "        return collection\n",
    "    \n",
    "    # Create collection schema\n",
    "    fields = [\n",
    "        FieldSchema(name=\"id\", dtype=DataType.VARCHAR, max_length=100, is_primary=True),\n",
    "        FieldSchema(name=\"repo\", dtype=DataType.VARCHAR, max_length=200),\n",
    "        FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=500),\n",
    "        FieldSchema(name=\"content\", dtype=DataType.VARCHAR, max_length=20000),\n",
    "        FieldSchema(name=\"chunk\", dtype=DataType.INT64),\n",
    "        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=EMBEDDING_DIMENSION)  # OpenAI text-embedding-3-small dimension\n",
    "    ]\n",
    "    \n",
    "    schema = CollectionSchema(fields=fields, description=\"Knowledge base for RAG\")\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "    \n",
    "    # Create index for vector search\n",
    "    index_params = {\n",
    "        \"metric_type\": \"COSINE\",\n",
    "        \"index_type\": \"IVF_FLAT\",\n",
    "        \"params\": {\"nlist\": 128}\n",
    "    }\n",
    "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "    \n",
    "    print(f\"Created new collection: {collection_name}\")\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a69e8c4-942a-4f2d-be18-599b6b2006a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def setup_github_sparse_collection():\n",
    "    \"\"\"Create or load a separate sparse collection for GitHub-only data (BM25-like).\"\"\"\n",
    "    collection_name = MILVUS_GITHUB_SPARSE_COLLECTION\n",
    "\n",
    "    if utility.has_collection(collection_name):\n",
    "        col = Collection(collection_name)\n",
    "        print(f\"Connected to existing sparse collection: {collection_name}\")\n",
    "    else:\n",
    "        fields = [\n",
    "            FieldSchema(name=\"id\", dtype=DataType.VARCHAR, max_length=200, is_primary=True),\n",
    "            FieldSchema(name=\"repo\", dtype=DataType.VARCHAR, max_length=200),\n",
    "            FieldSchema(name=\"path\", dtype=DataType.VARCHAR, max_length=1024),\n",
    "            FieldSchema(name=\"chunk\", dtype=DataType.INT64),\n",
    "            FieldSchema(name=\"sparse_emb\", dtype=DataType.SPARSE_FLOAT_VECTOR),\n",
    "        ]\n",
    "        schema = CollectionSchema(fields=fields, description=\"Sparse (BM25-like) index for GitHub files\")\n",
    "        col = Collection(name=collection_name, schema=schema)\n",
    "        # Create sparse index\n",
    "        index_params = {\n",
    "            \"metric_type\": \"IP\",\n",
    "            \"index_type\": \"SPARSE_INVERTED_INDEX\",\n",
    "            \"params\": {}\n",
    "        }\n",
    "        col.create_index(field_name=\"sparse_emb\", index_params=index_params)\n",
    "        print(f\"Created new sparse collection: {collection_name}\")\n",
    "    return col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba5735d2-86c5-42bf-878a-5e9f64f799fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def _fetch_github_files(repo_full_name: str) -> List[dict]:\n",
    "    token = GITHUB_PAT\n",
    "    if not token:\n",
    "        raise Exception(\"GITHUB_PAT not configured on server\")\n",
    "    try:\n",
    "        g = Github(token)\n",
    "        repo = g.get_repo(repo_full_name)\n",
    "        def walk(path: str = \"\") -> List[dict]:\n",
    "            acc = []\n",
    "            items = repo.get_contents(path)\n",
    "            for item in items:\n",
    "                if item.type == 'dir':\n",
    "                    acc.extend(walk(item.path))\n",
    "                else:\n",
    "                    if item.path.endswith((\".py\", \".md\", \".sql\", \".yml\")):\n",
    "                        acc.append({\"path\": item.path, \"content\": str(item.decoded_content, 'utf-8', errors='ignore')})\n",
    "            return acc\n",
    "        return walk(\"\")\n",
    "    except Exception as e:\n",
    "        raise (f\"GitHub access error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e256cd30-da40-43dc-bec1-a9b0fcc9c410",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Embedding functions\n",
    "async def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"Generate embedding for text using OpenAI API\"\"\"\n",
    "    try:\n",
    "        # Get OpenAI client\n",
    "        openai_client = get_openai_client()\n",
    "        \n",
    "        # Clean the text by removing newlines and extra whitespace\n",
    "        cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "        \n",
    "        # Create embedding using the OpenAI client\n",
    "        response = await openai_client.embeddings.create(\n",
    "            model=OPENAI_EMBEDDING_MODEL,\n",
    "            input=cleaned_text\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error generating embedding: {str(e)}\")\n",
    "\n",
    "def chunk_text_with_overlap(text: str, chunk_size: int = 2000, overlap: int = 200) -> List[str]:\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        chunks.append(text[start:end])\n",
    "        if end == len(text):\n",
    "            break\n",
    "        start = end - overlap\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "278c2bf6-47f3-4194-b2c8-e0b14763da8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def _tokenize(text: str) -> List[str]:\n",
    "    import re\n",
    "    tokens = re.findall(r\"[A-Za-z0-9_]+\", text.lower())\n",
    "    # basic filtering\n",
    "    return [t for t in tokens if len(t) >= 2]\n",
    "\n",
    "def _compute_sparse_embedding(text: str) -> dict:\n",
    "    \"\"\"Compute a simple TF-weighted sparse embedding mapped by hashed term ids.\"\"\"\n",
    "    from collections import Counter\n",
    "    terms = _tokenize(text)\n",
    "    if not terms:\n",
    "        return {}\n",
    "    counts = Counter(terms)\n",
    "    sparse = {}\n",
    "    for term, tf in counts.items():\n",
    "        idx = mmh3.hash(term, signed=False) % 1000000  # hash to a large dim space\n",
    "        weight = 1.0 + (tf ** 0.5)  # sublinear tf\n",
    "        sparse[idx] = weight\n",
    "    # Sort by index\n",
    "    return dict(sorted(sparse.items()))\n",
    "\n",
    "def chunk_text(text: str, max_len: int = 20000) -> List[str]:\n",
    "    return [text[i:i+max_len] for i in range(0, len(text), max_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d75ed64e-9ed0-469a-a861-5ae50bf0ee5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "async def ingest_github(repo: str, collection=None, collection_github_sparse=None):\n",
    "    \n",
    "    table_name = \"tabular.dataexpert.mlivshutz54984_vector_insert_log\"\n",
    "\n",
    "    # Use existing Milvus collection\n",
    "    if collection is None:\n",
    "        raise Exception(\"Milvus collection not initialized\")\n",
    "    if collection_github_sparse is None:\n",
    "        raise Exception(\"Milvus GitHub sparse collection not initialized\")\n",
    "    print(f\"[{datetime.datetime.now().isoformat()}] Starting ingestion for repo: {repo} into dense index: {collection.name} and sparse index: {collection_github_sparse.name}\")\n",
    "    # Upsert via Milvus SDK for this app\n",
    "    files = _fetch_github_files(repo)\n",
    "    count = 0\n",
    "    for f in files:\n",
    "        text = f.get(\"content\", \"\")\n",
    "        if not text:\n",
    "            continue\n",
    "        chunks = chunk_text_with_overlap(text)\n",
    "        for chunk_idx, chunk in enumerate(chunks):\n",
    "            try:\n",
    "                # Dense insert\n",
    "                emb = await get_embedding(chunk)\n",
    "                chunk_id = str(mmh3.hash128(repo + '/' + f[\"path\"] + f\"_chunk_{chunk_idx}\", signed=False))\n",
    "                data = [\n",
    "                    [chunk_id],                    # id\n",
    "                    [repo],                    # repo\n",
    "                    [f[\"path\"]],                   # title (without chunk number)\n",
    "                    [chunk],                       # content\n",
    "                    [chunk_idx],                   # chunk number\n",
    "                    [emb]                          # embedding\n",
    "                ]\n",
    "                collection.insert(data)\n",
    "                \n",
    "                # Sparse insert for the same chunk\n",
    "                sparse = _compute_sparse_embedding(chunk)\n",
    "                if sparse:\n",
    "                    sparse_data = [\n",
    "                        [chunk_id],\n",
    "                        [repo],\n",
    "                        [f[\"path\"]],                   # path (without chunk number)\n",
    "                        [chunk_idx],                   # chunk number\n",
    "                        [sparse]\n",
    "                    ]\n",
    "                    collection_github_sparse.insert(sparse_data)\n",
    "                \n",
    "                count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to create a dense or a sparse vector index: Skipping {f.get('path')} chunk {chunk_idx}: {e}\")\n",
    "                continue\n",
    "        end_time = datetime.datetime.now().isoformat()\n",
    "        log_list = [{\n",
    "            \"files_ingested\": count,\n",
    "            \"vector_index_type\": \"dense\",\n",
    "            \"collection\": collection.name,\n",
    "            \"created_at\": end_time,\n",
    "            \"repo\": repo,\n",
    "            \"file_name\": f.get(\"path\", \"\")\n",
    "        },\n",
    "        {\n",
    "            \"files_ingested\": count,\n",
    "            \"vector_index_type\": \"sparse\",\n",
    "            \"sparse_collection\": collection_github_sparse.name,\n",
    "            \"created_at\": end_time,\n",
    "            \"repo\": repo,\n",
    "            \"file_name\": f.get(\"path\", \"\")\n",
    "        }]\n",
    "        spark.createDataFrame(log_list).write.mode(\"append\").saveAsTable(table_name)\n",
    "        spark.sql(f\"alter table {table_name} set TBLPROPERTIES ('delta.enableChangeDataFeed' = true)\")\n",
    "\n",
    "    \n",
    "    collection.load()\n",
    "    collection_github_sparse.load()\n",
    "    print(f\"[{end_time}] Ingestion completed for repo: {repo}. Files ingested: {count}\")\n",
    "    \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c22e611a-5d6b-4217-84bc-53c6002ce9f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if OPENAI_API_KEY:\n",
    "    openai.api_key = OPENAI_API_KEY\n",
    "    # Explicitly create an httpx client without proxies\n",
    "    async_http_client = httpx.AsyncClient()\n",
    "    # async_http_client = httpx.AsyncClient(proxies=None)\n",
    "    client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY, http_client=async_http_client)\n",
    "else:\n",
    "    client = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36c21ca1-260a-456b-a22d-a3fe4e4b237e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    uri=ZILLIZ_CLOUD_URI,\n",
    "    token=ZILLIZ_API_KEY,\n",
    "    secure=True\n",
    ")\n",
    "print(\"Successfully connected to Zilliz Cloud!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c471efd-803f-45f9-8e89-480b2fb78dcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize collection\n",
    "collection = setup_milvus_collection(MILVUS_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d26d61fe-f347-4dfc-a06e-01283c6e3057",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "collection_github_sparse = setup_github_sparse_collection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07a2a66b-31cb-43b2-9aa4-e562a3929363",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ingest GitHub repo\n",
    "await ingest_github(repo, collection, collection_github_sparse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d21c8e2e-f4cf-418c-b9de-ea0cc6b4d763",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7640257831777985,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "add_github_repo_to_zilliz",
   "widgets": {
    "repo": {
     "currentValue": "mlivshutz/GenAI-In-Production-Databricks-FEB",
     "nuid": "aa2fb48d-1f25-4473-93c6-3d2337c12a8f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "GitHub Repo",
      "name": "repo",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "GitHub Repo",
      "name": "repo",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
